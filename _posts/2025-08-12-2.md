---
published: true
layout: single
title: "LLM 입문 하기 전에 기초 다지기 "
excerpt: "LLM, RAG 를 가지고 뭔가를 하고 싶은데 그 전에 뭐가 있는지 부터 알아가는 과정을 기록한다."
date: 2025-08-12
last_modified_at: 2025-08-12
categories: [AI]
tags: [LLM, RAG]
toc: true
---

# 0일차 — 환경 준비

* 목표: Windows에서 파이썬 가상환경 + LLM 기본 실행.
* 내용: `.venv` 구성, 필수 패키지 설치, GPU/CPU 설정, 첫 파이프라인 테스트.
* 실습: `pipeline("text-generation")`로 헬로월드.
* 완료 기준: 모델 로드·한 줄 생성 성공, 버전 고정 기록.

# 1일차 — LLM 기본 개념 & 생성 파이프라인

* 목표: 토큰→임베딩→Attention/FFN→logits→softmax 전체 흐름 이해.
* 내용: logit/확률, vocabulary size, special tokens 개념.
* 실습: temperature/top\_k/top\_p/repetition\_penalty/no\_repeat\_ngram\_size 실험.
* 완료 기준: 파라미터가 출력에 주는 영향 설명·데모 가능.

# 2일차 — 프롬프트 엔지니어링(기초)

* 목표: **역할(Role)·지시(Instruction)·예시(Few-shot)** 구조 습득.
* 내용: 시스템/유저/어시스턴트 메시지, 출력 포맷(JSON/Markdown) 강제.
* 실습: 같은 질문에 프롬프트만 바꿔 비교.
* 완료 기준: 과제별 프롬프트 템플릿 3종 작성.

# 3일차 — 토크나이저 & Vocabulary 심화

* 목표: BPE 동작, OOV 처리, special tokens(BOS/EOS/PAD).
* 내용: 토큰 ID↔문자열, add\_special\_tokens 옵션, 길이/단위.
* 실습: 한국어/영문 혼합 문장 토큰화, OOV 분해 관찰.
* 완료 기준: vocab\_size 의미 설명 + OOV 실습 결과 해석.

# 4일차 — 추론(Decoding) 전략

* 목표: Greedy, Beam, Sampling(top-k/top-p) 비교·선택 기준 습득.
* 내용: 동작 순서(temperature→top\_k→top\_p→sampling), beam 길이 패널티.
* 실습: 동일 프롬프트로 전략별 결과·속도 비교.
* 완료 기준: 작업별(요약/번역/대화) 최적 전략 선택 근거 제시.

# 5일차 — Pretraining vs Fine-tuning + LoRA/QLoRA

* 목표: 사전학습/미세조정 차이와 저랭크 학습 이해.
* 내용: SFT/Instruction/Chat 튜닝, LoRA(r/alpha/target\_modules), QLoRA(4bit).
* 실습: SFTTrainer + LoRA 구조 세팅(미니 데이터로 드라이런).
* 완료 기준: 학습 파이프라인 코드 설명·수정 가능.

# 6일차 — 프롬프트 구조 & 컨텍스트 윈도우

* 목표: 컨텍스트 제한과 긴 문서 처리.
* 내용: 윈도우/슬라이딩/요약 삽입, stop 시퀀스, truncation 전략.
* 실습: 긴 문서 토큰 길이 측정→슬라이딩 윈도우 적용.
* 완료 기준: 길이 제약 하에서 품질 유지 전략 제시.

## 학습 내용
 - 컨텍스트 윈도우 제한을 초과하는 긴 문서의 경우 아래 단계를 통해 처리 된다.
   1. 정리/중복 제거
   2. 선별
   3. 요약
   4. 압축
   5. 우선순위 절단
 - 각 단계별 진행 여부는 토큰 게이트와 품질 게이트 기준을 만족하지 않으면 다음 단계로 넘어간다.
   - 토큰 게이트(TG)는 현재 계산된 프롬프트(입력 토큰)의 길이가 모델의 컨텍스트 윈도우 안에 들어오는지 판정하는 규칙.
     - 핵심 개념
       - 전체 윈도우: W = (시스템/지시 S) + (본문 입력 I) + (출력 O)
       - 입력 예산 B는 목표 출력과 시스템/지시를 빼고 본문 입력에 쓸 수 있는 최대치
         → B = W - O - S
     - 예시
       - 윈도우 W = 8,000
       - 시스템/지시 S = 300
       - 목표 출력 O = 1,000
       - → B = 8,000 - 1,000 - 300 = 6,700
       - → 컨텍스트+질문(+예시 등) 합계가 6,700 토큰 이하여야 안전(여유를 두고 ×0.95 정도로 운용 권장).
   - 품질 게이트(QG)는 토큰을 줄인 뒤에도 정답 품질이 유지되는지 확인하는 규칙.

 - 학습 내용 요약 : 긴 문서를 컨텍스트 윈도우의 크기에 맞게 안정적으로 처리 하기 위한 방법에 관한 내용이었다.

## Q & A

1. **프롬프트 구조와 컨텍스트 윈도우의 관계는?**  
   - 컨텍스트 윈도우는 입력과 출력 가능한 토큰의 최대 용량을 말한다.
     예를 들어 컨텍스트 윈도우가 4K 라면 입력과 출력 토큰은 최대 4K 를 넘을수 없다.
   - 프롬프트 구조는 일반적으로 아래와 같은 구조를 가진다.
     1. 시스템 메시지
     2. 컨텍스트(지식/배경정보)
     3. 질문 또는 지시사항
     4. 예시
   
2. **chatgpt.com 의 웹 버전 대화형 인터페이스에서 프롬프트 구조를 사용해 보면?**
   - 아래와 같이 필요한 항목만 프롬프트에 포함하여 작성하였다.
   <pre>
   [시스템 메시지]
   1.당신은 AI, LLM, RAG 분야의 전문가 입니다.
   2.설명은 단계별로 하고 이해하기 쉬운 표현을 사용하여 작성합니다.

   [지시사항]
   1. 주어진 주제를 체계적으로 설명합니다.  
   2. 각 단계별로 번호를 매기고, 핵심 개념 → 예시 → 응용 순서로 구성합니다.  
   3. 불필요한 전문용어는 배제하거나, 반드시 쉬운 설명을 덧붙입니다.  
   4. 설명이 끝나면 간단한 요약을 제공합니다.

   [질문]
   few-shot 의 개념과 왜 사용하는지 목적에 대해 설명해줘.
   </pre>  
   - 프롬프트를 여러번 요청하면 그때마다 답변은 모두 다르게 나왔지만 프롬프트에 입력한 사항들을 지키는 것은 일관성이 있어 보였다.

# 7일차 — 임베딩(Embeddings) 기초

* 목표: 임베딩 벡터와 유사도 지표 이해.
* 내용: 코사인/내적/유클리드, 정규화, 차원/분산.
* 실습: 한국어 임베딩 모델 2\~3종 비교, 쿼리-문서 유사도 Top-N.
* 완료 기준: 임베딩 선택·전처리(정규화) 근거 설명.

## 학습 내용
 - 수학적인 부분을 배제하고 임베딩 벡터와 유사도 지표가 어떤것을 의미하는지 확인.
 - **임베딩 벡터** : 텍스트(또는 이미지, 오디오 등)를 고정 길이의 숫자 배열로 변환한 것.
   - 사용 목적 : 사람이 이해하는 문장을 기계가 계산할 수 있는 형태로 변환.
     - 숫자 배열로 변환하기 전에 먼저 문장을 토큰(정수ID)으로 변경해야 한다.
 - **유사도 지표** : 두 개의 임베딩 벡터가 얼마나 비슷한지 계산하는 기준.
   - "A 질문"과 "B 문서"가 서로 얼마나 관련 있는지 점수화.
   - 종류
     1. 코사인 유사도 – 방향이 얼마나 같은지 비교
     2. 내적(Dot Product) – 방향 + 길이까지 반영
     3. 유클리드 거리 – 두 점(벡터) 사이의 직선 거리

| 순위 | 지표      | 비교 방식    | 주 사용 영역         | 예시                  |
| -- | ------- | -------- | --------------- | ------------------- |
| 1  | 코사인 유사도 | 방향 비교    | 텍스트 검색, RAG, 챗봇 | FAQ 검색, 의미 기반 문서 검색 |
| 2  | 내적      | 방향+길이    | 추천, 광고 랭킹       | 상품 추천, 광고 점수 계산     |
| 3  | 유클리드 거리 | 절대 거리    | 이미지·위치 비교       | 이미지 검색, 위치 기반 서비스   |
| 4  | 맨해튼 거리  | 절대값 차이 합 | 시계열, 격자 데이터     | 금융 이상거래 탐지, 게임 AI   |
| 5  | 자카드 유사도 | 교집합/합집합  | 태그, 키워드 비교      | 뉴스 추천, 친구 관계 분석     |     

## Q & A
1. **유사도 지표 중 많이 사용되는 것은?**
   - 1위. 코사인 유사도(Cosine Similarity)
     - 검색·RAG·챗봇에서 거의 표준
     - 벡터의 방향만 비교. 의미가 비슷하면 높은 점수
     - 텍스트 길이나 크기 차이에 영향을 덜 받음.
     - 예시
       - FAQ 검색: "배송 조회는 어떻게 하나요?" → "택배 추적 방법 안내"와 높은 유사도
       - RAG: 쿼리 문장과 벡터 DB의 문서 간 의미 비교
       - 챗봇 Q&A: 말투가 달라도 같은 의미면 잘 매칭됨
   - 2위. 내적 (Dot Product / Inner Product)
     - 추천·랭킹·임베딩 학습 단계에서 자주 사용
     - 방향 + 벡터 길이까지 반영.
     - 벡터 크기에 의미가 있는 경우 유리
       - 벡터 크기는 강도(확신, 선호, 특징의 세기)를 나타낼 수 있음
       - 내적은 의미(방향) + 강도(크기) 모두 반영 → 강도가 중요한 추천·랭킹에 유리
       - 코사인 유사도는 강도를 무시하고 의미만 본다는 점에서 차이가 있음
       - 예시
         - 방향 = "둘 다 피자를 좋아한다"
         - 크기 = "얼마나 좋아하느냐"
         - 코사인 유사도는 “둘 다 피자를 좋아하네?” 정도만 판단
         - 내적은 “둘 다 피자를 좋아하는데, 이 사람은 진짜 엄청 좋아하네! 점수 더 줘야겠다”라고 판단

2. **정규화(Normalization) 란?**
   - 정규화는 벡터의 길이(크기) 차이의 영향을 없애고, 방향(의미)만 비교 할때 사용한다.
   - 긴 문서나 반복이 많은 텍스트는 임베딩 벡터의 크기가 커서 의미가 비슷하더라도 평가 점수에서 이득을 보게 됨.
   - 유사도 지표(코사인 또는 내적)에 따라 정규화를 적용하거나 하지 않을 수 있지만, 의미 비교를 위해서라면 사실상 필수임.
   - 반대로 추천/광고/랭킹 같은 선호도를 의도적으로 반영하고 싶다면 임베딩의 크기가
   - 예시
     - 상황: “반품 절차”를 묻는 쿼리로 사내 가이드를 검색.
     - 조각 A: 핵심만 짧게 정리 (짧음)
     - 조각 B: 같은 내용 + 부연 + 경고문(길음)
     - 정규화 없음: B가 길이 때문에 내적 점수 우세 → B가 Top1
     - 정규화 적용: A와 B가 의미 기준으로 비슷하게 평가 → 실제로 더 적합한 문서가 Top에 옴

3. **벡터의 길이(크기, magnitude)란?**
   - 벡터는 여러 개의 숫자로 구성된 좌표
   - 벡터의 길이 = 원점(0,0,…,0)에서 해당 좌표까지의 “거리”.
     - 쉽게 말하면, 해당 벡터가 원점에서 얼마나 멀리 떨어져 있는지를 나타내는 값.
    
4. **벡터의 길이(크기) 값으로 가중치를 준다는 것은?**
   - 유사도 지표 중 내적을 기준으로 계산할 경우 길이가 더 높은 점수를 받게 된다.
   - 벡터값을 저장할때 가중치를 더하여 저장을 하더라도 정규화를 거치게 되면 의미만 남게 된다.
   - 정규화를 하지 않는다면 해당 점수를 그대로 사용 하겠지만 어떠한 이유에 의해 정규화가 필요하다면?
     - 재랭킹(Re-ranking) 과정을 통해 가중치를 부여하는 별도의 과정이 필요하다. 

5. **유사도 점수 + 인기 점수 + 최신성 점수 를 결합해 최종 랭킹을 만드는 예제**
<details markdown="1">
<summary>코드보기</summary>
  
  ```python
  import numpy as np
from datetime import datetime

# -----------------------------
# 유틸 함수
# -----------------------------
def l2_normalize(v):
    n = np.linalg.norm(v)
    return v if n == 0 else v / n

def cosine_similarity(a, b):
    return float(np.dot(l2_normalize(a), l2_normalize(b)))

def minmax_scale(x, min_x, max_x):
    if max_x == min_x:
        return 0.0
    return (x - min_x) / (max_x - min_x)

def recency_score_by_days(days_ago, half_life_days=14):
    """
    지수감쇠 최신성 점수: 오늘 문서=1.0, 오래될수록 0에 수렴
    half_life_days: 절반으로 떨어지는 기간
    """
    return 0.5 ** (days_ago / float(half_life_days))

# -----------------------------
# 샘플 데이터 (문서 3개)
# -----------------------------
today = datetime(2025, 8, 13)

docs = [
    {
        "id": "docA",
        "title": "배송 조회 방법",
        "embedding": np.array([0.12, 0.33, 0.55, 0.01, 0.27]),
        "views": 1200,                     # 인기 지표 예시
        "updated_at": datetime(2025, 8, 12) # 최신성 지표 예시(어제)
    },
    {
        "id": "docB",
        "title": "반품/교환 절차",
        "embedding": np.array([0.09, 0.29, 0.50, 0.05, 0.30]),
        "views": 500,
        "updated_at": datetime(2025, 7, 30)
    },
    {
        "id": "docC",
        "title": "해외 배송 안내",
        "embedding": np.array([0.40, 0.10, 0.07, 0.02, 0.03]),
        "views": 3000,
        "updated_at": datetime(2025, 6, 10)
    },
]

# 쿼리
query_text = "배송을 어떻게 조회하나요?"
# 실제 서비스에서는 임베딩 모델 호출로 구하지만, 여기선 샘플 벡터 가정
query_embedding = np.array([0.10, 0.31, 0.52, 0.02, 0.25])

# -----------------------------
# (A) 재랭킹 가중치 방식 (정규화 유지 + 코사인)
#     - 의미 비교는 공정하게(정규화)
#     - 인기/최신성은 별도 점수로 결합
# -----------------------------
# 1) 메타 점수 계산(0~1 스케일)
view_vals = [d["views"] for d in docs]
min_v, max_v = min(view_vals), max(view_vals)

for d in docs:
    # 코사인 유사도
    d["sim_cosine"] = cosine_similarity(query_embedding, d["embedding"])

    # 인기 점수(0~1)
    d["pop_score"] = minmax_scale(d["views"], min_v, max_v)

    # 최신성 점수(0~1)
    days_ago = (today - d["updated_at"]).days
    d["recency_score"] = recency_score_by_days(days_ago, half_life_days=14)

# 2) 가중치 결합
w_sim, w_pop, w_rec = 0.70, 0.20, 0.10  # 필요 시 A/B로 튜닝
for d in docs:
    d["final_score_rerank"] = (
        w_sim * d["sim_cosine"]
        + w_pop * d["pop_score"]
        + w_rec * d["recency_score"]
    )

ranked_rerank = sorted(docs, key=lambda x: x["final_score_rerank"], reverse=True)

print("=== (A) 재랭킹 가중치 방식 결과 ===")
for i, d in enumerate(ranked_rerank, 1):
    print(f"{i}. {d['id']} | sim={d['sim_cosine']:.3f} "
          f"pop={d['pop_score']:.2f} rec={d['recency_score']:.2f} "
          f"FINAL={d['final_score_rerank']:.3f} | {d['title']}")

# -----------------------------
# (B) 벡터 크기 조정 방식 (dot-product + no normalization)
#     - 의미 + 강도(크기)를 내적에서 직접 반영
#     - 주의: 코사인/정규화 쓰면 효과 사라짐
# -----------------------------
# 예: '자주 검색되는 글' boost_factor로 임베딩 크기 키우기
boost_map = {
    "docA": 1.0,   # 평범
    "docB": 1.2,   # 조금 boost
    "docC": 1.5,   # 많이 boost (예: 매우 자주 검색됨)
}

# dot-product 기반 점수
for d in docs:
    boosted = d["embedding"] * boost_map[d["id"]]
    d["dot_no_norm"] = float(np.dot(query_embedding, boosted))

ranked_dot = sorted(docs, key=lambda x: x["dot_no_norm"], reverse=True)

print("\n=== (B) 벡터 크기 조정 방식 결과 (dot-product, no norm) ===")
for i, d in enumerate(ranked_dot, 1):
    print(f"{i}. {d['id']} | dot={d['dot_no_norm']:.3f} "
          f"(boost={boost_map[d['id']]}) | {d['title']}")
  ```
  
</details>

# 8일차 — 벡터 스토어 선택과 구축

* 목표: FAISS vs Elasticsearch/OpenSearch 아키텍처 비교.
* 내용: HNSW/IVF/Flat, 인덱스·파라미터(efSearch/nprobe) 개념.
* 실습: FAISS 인덱스 구축·검색, ES KNN 간단 비교.
* 완료 기준: PoC/프로덕션 각각의 최선 선택안 제시.

# 9일차 — 청킹(Chunking) & 검색 품질 향상

* 목표: 청킹 전략이 검색 품질에 미치는 영향 이해.
* 내용: 문장/문단/토큰 기반, 오버랩, 메타데이터(섹션/제목/태그).
* 실습: 동일 코퍼스에 전략별 검색 성능 비교(MMR·RRR 등).
* 완료 기준: 프로젝트에 맞는 청킹 파라미터 결정.

# 10일차 — 리랭킹(Reranking)

* 목표: retriever 상위 k 재정렬로 정답률 향상.
* 내용: Cross-encoder(bge-reranker 등), 레이턴시/비용 트레이드오프.
* 실습: 검색→리랭킹 전/후 정답률·클릭로그 비교.
* 완료 기준: 리랭킹 도입 기준과 임계치(Top-K, 임계 스코어) 정의.

# 11일차 — RAG 파이프라인 조립(End-to-End)

* 목표: Retriever → (Reranker) → Generator 통합.
* 내용: 컨텍스트 주입 프롬프트, 출처 인용, 쿼리 확장(hyDE 등).
* 실습: 질문→검색→생성→인용까지 작동하는 E2E 구축.
* 완료 기준: 로컬 데모 API(예: FastAPI) 제공.

# 12일차 — RAG 평가 & 자동화

* 목표: 정량/정성 평가 체계 수립.
* 내용: RAGAS/LLM-as-Judge, Faithfulness/Groundedness 지표.
* 실습: 미니 테스트셋으로 자동 평가 파이프라인 실행.
* 완료 기준: 기준치 미달 케이스 자동 리포트 생성.

# 13일차 — 운영·배포(백엔드 관점)

* 목표: 서비스 레디 파이프라인.
* 내용: FastAPI/스트리밍, **Spring Boot 연동**(REST/gRPC), 캐시 전략, 타임아웃/재시도.
* 실습: 자바 백엔드에서 RAG API 호출·리트라이·서킷브레이커.
* 완료 기준: 운영용 설정값(타임아웃/병렬/캐시) 문서화.

# 14일차 — 보안·최적화·가드레일

* 목표: 안전·성능·비용 최적화.
* 내용: 프롬프트 인젝션 방어, 데이터 유출 차단, 권한 분리, 양자화(AWQ/GPTQ/4-bit), 가드레일(금칙어/정책 프롬프트).
* 실습: 어뷰징 프롬프트 테스트 & 방어 템플릿 적용, 4bit 추론 속도 비교.
* 완료 기준: 보안 체크리스트 + 성능/비용 벤치 결과.

---
