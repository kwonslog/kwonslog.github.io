---
layout: single
title: "로컬 PC에서 LLM 학습 시도"
excerpt: "로컬 PC 에서 공개된 LLM 모델을 이용한 추가 학습 테스트"
date: 2025-08-13
last_modified_at: 2025-08-13
categories: [AI]
tags: [LLM, DAPT]
toc: true
---

# 공개된 LLM 모델을 이용한 학습 시도
- DAPT (Domain-Adaptive Pretraining, 도메인 적응 사전학습)
  - 기존에 사전학습(pretraining)을 마친 LLM을 특정 도메인의 대규모 텍스트로 다시 사전학습하는 과정입니다.
  - 목적 : 모델의 어휘·문장 패턴·지식 구조를 해당 도메인으로 전반적으로 맞추기.
  - 학습 범위 : 모든 모델 파라미터를 업데이트 (Full model update).
  - 데이터 규모 : 일반적으로 수백 MB~수십 GB 단위의 대규모 비라벨(unsupervised) 텍스트 필요.
  - 결과 : 모델이 해당 도메인에 특화된 언어 이해와 생성 능력을 보유하게 됨.
- PEFT (Parameter-Efficient Fine-Tuning, 파라미터 효율적 파인튜닝)
  - LLM 전체를 재학습하지 않고 일부 파라미터만 학습하거나, 추가 모듈(LoRA, Prefix-tuning 등)만 붙여서 학습하는 방법.
  - 목적 : 적은 자원·시간·저장 공간으로 특정 태스크나 도메인에 맞춘 모델 튜닝.
  - 학습 범위 : 일부 파라미터 또는 추가된 적은 수의 가중치만 학습.
  - 데이터 규모 : 수 MB~수백 MB의 라벨 데이터 또는 소량의 도메인 데이터로 가능.
  - 결과 : 원본 모델의 범용 성능은 유지하면서도, 필요한 작업에서만 특화된 성능 발휘.
- 다음 순서로 LLM 학습을 시도한다.
  1. PEFT
  2. DAPT

## 1. PEFT 보다 더 빠르게 학습 시킬 수 있는 방법은?

### 1.1 프롬프트 엔지니어링(Prompt Engineering, 프롬프트 엔지니어링)

* **설명**
  모델을 전혀 학습하지 않고, \*\*프롬프트(입력 문장)\*\*를 잘 설계해서 원하는 출력을 유도.
* **속도 장점**
  학습이 없으니 0초. 즉시 적용 가능.
* **단점**
  복잡한 태스크나 일관성 높은 출력에는 한계.
* **비유**
  요리사를 새로 교육시키는 대신, **레시피를 매우 상세하게 써서** 원하는 맛이 나오게 하는 것.

### 1.2 RAG(Retrieval-Augmented Generation, 리트리벌 어그멘티드 제너레이션)

* **설명**
  모델을 학습하지 않고, 외부 지식베이스(Vector DB 등)에서 관련 정보를 찾아 모델 입력에 함께 제공.
* **속도 장점**
  학습 과정 없음. 데이터 업데이트도 검색DB 갱신만 하면 됨.
* **단점**
  검색 품질에 따라 결과 품질이 달라짐.
* **비유**
  셰프가 요리를 할 때 **머릿속 기억 대신 요리책을 바로 찾아보는 방식**.

### 1.3 어댑터 체인(Adapters) 로드 앤 플레이

* **설명**
  다른 사람이 이미 학습한 **LoRA / Adapters**를 다운로드해서 원본 모델에 붙여 사용.
* **속도 장점**
  학습 없이 즉시 로드 → 몇 초\~몇 분 안에 사용 가능.
* **단점**
  원하는 작업에 맞는 어댑터가 있어야 함.
* **비유**
  새로 교육시키는 대신 **이미 교육된 직원을 바로 채용**.

## 2. 초경량 학습 방법 (PEFT보다 빠름)

### 2.1 Prompt-tuning / Prefix-tuning (프롬프트 튜닝 / 프리픽스 튜닝)

* **설명**
  모델의 입력 앞에 붙는 \*\*작은 벡터(프리픽스)\*\*만 학습.
* **학습 데이터·시간**
  PEFT보다 학습 파라미터 수가 더 적음 → CPU에서도 수십 분\~몇 시간.
* **장점**
  메모리/연산량 최소, 다중 태스크에도 유연.
* **단점**
  도메인 전반 지식 적응력은 약함.
* **비유**
  요리사 전체 교육 대신 **짧은 암기문구**만 외워서 레시피를 변형.

### 2.2 BitFit (비트핏)

* **설명**
  \*\*Bias term(편향 값)\*\*만 학습.
* **학습 파라미터**
  전체의 0.1% 이하 → 극도로 적음.
* **장점**
  매우 가벼움, CPU에서도 빠르게 가능.
* **단점**
  복잡한 태스크에서는 성능 향상 제한.
* **비유**
  요리사의 **손맛만 살짝 조절**하는 수준.

### 2.3 Low-rank LoRA (초저랭크)

* **설명**
  LoRA rank 값을 아주 작게 줄여 학습량 최소화.
* **장점**
  기존 PEFT보다 빠름, VRAM/메모리 절감.
* **단점**
  성능 하락 위험.

## 3. CPU 환경에서 현실적인 순위 (빠른 순서)
 1. **프롬프트 엔지니어링 / RAG** (학습 없음)
 2. **프리픽스 튜닝 / 비트핏** (몇 분~몇 시간)
 3. **저랭크 LoRA** (수시간~수일)
 4. **기본 PEFT** (수시간~수일)
 5. **DAPT** (수일~수주)

# LLM 학습에 적합한 GPU 체크
- 개인 노트북에서 테스트 할 것이기 때문에 학습을 위한 GPU 사용이 가능한지 확인 한다.
- 윈도우 11 OS 기준. cmd 창에서 nvidia-smi 명령을 실행하면 다음과 같이 출력 된다.
<img width="1262" height="302" alt="image" src="https://github.com/user-attachments/assets/a93e843e-2671-4c01-9146-db7bde498116" />
- 여기서 GPU 모델과 VRAM, CUDA 버전을 확인 할 수 있다.

# 체크리스트
- [ ] 추가 학습에 사용할 최소 용량의 데이터 준비하기
- [ ] 추가 학습한 내용에 대한 프롬프트 작성 및 실행하기
- [ ] 프롬프트 결과에 대한 평가 방법 확인하기
- [ ] GPU 없이 CPU 만 사용 했을때 가능한 추가 학습 데이터와 LLM 모델 스펙 확인하기
- [ ] 
